{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRIBUTES = {\"race\": 1,\n",
    "              \"gender\": 2,\n",
    "              \"age\": 3,\n",
    "              \"skintone\": 4,\n",
    "              \"emotion\": 5,\n",
    "              \"masked\": 6}\n",
    "attribute_name = \"race\"\n",
    "attrs = ATTRIBUTES[attribute_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2 as ToTensor\n",
    "\n",
    "\n",
    "def get_img_trans(phase,\n",
    "                  image_size=256,\n",
    "                  crop_size=224,\n",
    "                  mean=(0.485, 0.456, 0.406),\n",
    "                  std=(0.229, 0.224, 0.225)):\n",
    "    normalize = A.Normalize(mean=mean, std=std)\n",
    "    if phase == \"train\":\n",
    "        return A.Compose(\n",
    "            [\n",
    "                A.Resize(image_size, image_size),\n",
    "                A.RandomCrop(crop_size, crop_size),\n",
    "                A.HorizontalFlip(),\n",
    "                normalize,\n",
    "                ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "    elif phase in [\"test\", \"val\"]:\n",
    "        return A.Compose(\n",
    "            [\n",
    "                A.Resize(image_size, image_size),\n",
    "                A.CenterCrop(crop_size, crop_size),\n",
    "                normalize,\n",
    "                ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        raise KeyError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class FaceDataset(Dataset):\n",
    "    \"\"\"Fashion Color dataset.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 root_dir,\n",
    "                 image_list,\n",
    "                 mean,\n",
    "                 std,\n",
    "                 image_size,\n",
    "                 crop_size,\n",
    "                 mode=\"train\",\n",
    "                 transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(image_list, delimiter=\" \", header=None)\n",
    "        self.data = np.array(self.data)\n",
    "        self.root_dir = root_dir\n",
    "        if transform:\n",
    "            self.transform = get_img_trans(mode,\n",
    "                                           image_size=image_size,\n",
    "                                           crop_size=crop_size,\n",
    "                                           mean=mean,\n",
    "                                           std=std)\n",
    "        self.age_classes = 6\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_path = osp.join(self.root_dir, self.data[idx][0])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = self.data[idx][1:]\n",
    "        target = {\"race\": label[0],\n",
    "                  \"gender\": label[1],\n",
    "                  \"age\": label[2],\n",
    "                  \"skintone\": label[3],\n",
    "                  \"emotion\": label[4],\n",
    "                  \"masked\": label[5]}\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        label = self._transform_ages_to_one_hot_ordinal(target,\n",
    "                                                        self.age_classes\n",
    "                                                        )\n",
    "        return image, label\n",
    "\n",
    "    def _transform_ages_to_one_hot_ordinal(self, target, age_classes):\n",
    "        age = target[\"age\"]\n",
    "        new_age = np.zeros(shape=age_classes)\n",
    "        new_age[:age] = 1\n",
    "        target[\"age\"] = new_age\n",
    "        return target\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from lightning import LightningDataModule\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "\n",
    "class FashionDataModule(LightningDataModule):\n",
    "    \"\"\"`LightningDataModule` for the Fashion-Color dataset.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir: str = \"data/interim\",\n",
    "        image_train_list: str = \"face.csv\",\n",
    "        image_test_list: str = \"face.csv\",\n",
    "        val_test_split: Tuple[float, float] = (0.5, 0.5),\n",
    "        batch_size: int = 64,\n",
    "        num_workers: int = 0,\n",
    "        pin_memory: bool = False,\n",
    "        mean: Tuple[float, float, float] = (0.485, 0.456, 0.406),\n",
    "        std: Tuple[float, float, float] = (0.229, 0.224, 0.225),\n",
    "        image_size: int = 256,\n",
    "        crop_size: int = 224\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize a `FashionDataModule`.\n",
    "\n",
    "        :param data_dir: The data directory. Defaults to `\"data/\"`.\n",
    "        :param train_val_test_split: The train, validation and test split. Defaults to `(55_000, 5_000, 10_000)`.\n",
    "        :param batch_size: The batch size. Defaults to `64`.\n",
    "        :param num_workers: The number of workers. Defaults to `0`.\n",
    "        :param pin_memory: Whether to pin memory. Defaults to `False`.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # this line allows to access init params with 'self.hparams' attribute\n",
    "        # also ensures init params will be stored in ckpt\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "        self.data_train: Optional[Dataset] = None\n",
    "        self.data_val: Optional[Dataset] = None\n",
    "        self.data_test: Optional[Dataset] = None\n",
    "\n",
    "        self.batch_size_per_device = batch_size\n",
    "\n",
    "    @property\n",
    "    def num_classes(self) -> int:\n",
    "        \"\"\"Get the number of classes.\n",
    "\n",
    "        :return: The number of different colors (15).\n",
    "        \"\"\"\n",
    "        return 15\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        \"\"\"Download data if needed. Lightning ensures that `self.prepare_data()` is called only\n",
    "        within a single process on CPU, so you can safely add your downloading logic within. In\n",
    "        case of multi-node training, the execution of this hook depends upon\n",
    "        `self.prepare_data_per_node()`.\n",
    "\n",
    "        Do not use it to assign state (self.x = y).\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        \"\"\"Load data. Set variables: `self.data_train`, `self.data_val`, `self.data_test`.\n",
    "\n",
    "        This method is called by Lightning before `trainer.fit()`, `trainer.validate()`, `trainer.test()`, and\n",
    "        `trainer.predict()`, so be careful not to execute things like random split twice! Also, it is called after\n",
    "        `self.prepare_data()` and there is a barrier in between which ensures that all the processes proceed to\n",
    "        `self.setup()` once the data is prepared and available for use.\n",
    "\n",
    "        :param stage: The stage to setup. Either `\"fit\"`, `\"validate\"`, `\"test\"`, or `\"predict\"`. Defaults to ``None``.\n",
    "        \"\"\"\n",
    "        # Divide batch size by the number of devices.\n",
    "        if self.trainer is not None:\n",
    "            if self.hparams.batch_size % self.trainer.world_size != 0:\n",
    "                raise RuntimeError(\n",
    "                    f\"Batch size ({self.hparams.batch_size}) is not divisible by the number of devices ({self.trainer.world_size}).\"\n",
    "                )\n",
    "            self.batch_size_per_device = (\n",
    "                self.hparams.batch_size // self.trainer.world_size\n",
    "            )\n",
    "\n",
    "        # load and split datasets only if not loaded already\n",
    "        if not self.data_train and not self.data_val and not self.data_test:\n",
    "            self.data_train = FaceDataset(\n",
    "                self.hparams.root_dir,\n",
    "                self.hparams.image_train_list,\n",
    "                self.hparams.mean,\n",
    "                self.hparams.std,\n",
    "                self.hparams.image_size,\n",
    "                self.hparams.crop_size,\n",
    "                mode=\"train\",\n",
    "                transform=True,\n",
    "            )\n",
    "            testset = FaceDataset(\n",
    "                self.hparams.root_dir,\n",
    "                self.hparams.image_test_list,\n",
    "                self.hparams.mean,\n",
    "                self.hparams.std,\n",
    "                self.hparams.image_size,\n",
    "                self.hparams.crop_size,\n",
    "                mode=\"test\",\n",
    "                transform=True,\n",
    "            )\n",
    "\n",
    "            val_size = int(self.hparams.val_test_split[0] * len(testset))\n",
    "            test_size = len(testset) - val_size\n",
    "\n",
    "            self.data_val, self.data_test = random_split(\n",
    "                dataset=testset,\n",
    "                lengths=[val_size, test_size],\n",
    "                generator=torch.Generator().manual_seed(42),\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader[Any]:\n",
    "        \"\"\"Create and return the train dataloader.\n",
    "\n",
    "        :return: The train dataloader.\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            dataset=self.data_train,\n",
    "            batch_size=self.batch_size_per_device,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader[Any]:\n",
    "        \"\"\"Create and return the validation dataloader.\n",
    "\n",
    "        :return: The validation dataloader.\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            dataset=self.data_val,\n",
    "            batch_size=self.batch_size_per_device,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader[Any]:\n",
    "        \"\"\"Create and return the test dataloader.\n",
    "\n",
    "        :return: The test dataloader.\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            dataset=self.data_test,\n",
    "            batch_size=self.batch_size_per_device,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "    def teardown(self, stage: Optional[str] = None) -> None:\n",
    "        \"\"\"Lightning hook for cleaning up after `trainer.fit()`, `trainer.validate()`,\n",
    "        `trainer.test()`, and `trainer.predict()`.\n",
    "\n",
    "        :param stage: The stage being torn down. Either `\"fit\"`, `\"validate\"`, `\"test\"`, or `\"predict\"`.\n",
    "            Defaults to ``None``.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def state_dict(self) -> Dict[Any, Any]:\n",
    "        \"\"\"Called when saving a checkpoint. Implement to generate and save the datamodule state.\n",
    "\n",
    "        :return: A dictionary containing the datamodule state that you want to save.\n",
    "        \"\"\"\n",
    "        return {}\n",
    "\n",
    "    def load_state_dict(self, state_dict: Dict[str, Any]) -> None:\n",
    "        \"\"\"Called when loading a checkpoint. Implement to reload datamodule state given datamodule\n",
    "        `state_dict()`.\n",
    "\n",
    "        :param state_dict: The datamodule state returned by `self.state_dict()`.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = FaceDataset(\n",
    "    \"/media/gnort/HDD6/Study/face-analysis-lightning/dataset/face/cropped_faces\",\n",
    "    \"/media/gnort/HDD6/Study/face-analysis-lightning/dataset/face/image_lists/face_train.txt\",\n",
    "    [0.485, 0.456, 0.406],\n",
    "    [0.229, 0.224, 0.225],\n",
    "    256,\n",
    "    224,\n",
    "    mode=\"train\",\n",
    "    transform=True,\n",
    ")\n",
    "dataloader_train = DataLoader(\n",
    "            dataset=data_train,\n",
    "            batch_size=32,\n",
    "            num_workers=4,\n",
    "            pin_memory=False,\n",
    "            shuffle=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "{'race': tensor([0, 0, 0, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0]), 'gender': tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0]), 'age': tensor([[1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.]], dtype=torch.float64), 'skintone': tensor([3, 1, 3, 1, 3, 3, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 3, 1, 1, 3, 1, 1, 1]), 'emotion': tensor([4, 4, 4, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 4, 3, 3, 3, 3, 3, 4]), 'masked': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"conv1_7x7_s2.weight\", \"conv1_7x7_s2_bn.weight\", \"conv1_7x7_s2_bn.bias\", \"conv1_7x7_s2_bn.running_mean\", \"conv1_7x7_s2_bn.running_var\", \"conv2_1_1x1_reduce.weight\", \"conv2_1_1x1_reduce_bn.weight\", \"conv2_1_1x1_reduce_bn.bias\", \"conv2_1_1x1_reduce_bn.running_mean\", \"conv2_1_1x1_reduce_bn.running_var\", \"conv2_1_3x3.weight\", \"conv2_1_3x3_bn.weight\", \"conv2_1_3x3_bn.bias\", \"conv2_1_3x3_bn.running_mean\", \"conv2_1_3x3_bn.running_var\", \"conv2_1_1x1_increase.weight\", \"conv2_1_1x1_increase_bn.weight\", \"conv2_1_1x1_increase_bn.bias\", \"conv2_1_1x1_increase_bn.running_mean\", \"conv2_1_1x1_increase_bn.running_var\", \"conv2_1_1x1_proj.weight\", \"conv2_1_1x1_proj_bn.weight\", \"conv2_1_1x1_proj_bn.bias\", \"conv2_1_1x1_proj_bn.running_mean\", \"conv2_1_1x1_proj_bn.running_var\", \"conv2_2_1x1_reduce.weight\", \"conv2_2_1x1_reduce_bn.weight\", \"conv2_2_1x1_reduce_bn.bias\", \"conv2_2_1x1_reduce_bn.running_mean\", \"conv2_2_1x1_reduce_bn.running_var\", \"conv2_2_3x3.weight\", \"conv2_2_3x3_bn.weight\", \"conv2_2_3x3_bn.bias\", \"conv2_2_3x3_bn.running_mean\", \"conv2_2_3x3_bn.running_var\", \"conv2_2_1x1_increase.weight\", \"conv2_2_1x1_increase_bn.weight\", \"conv2_2_1x1_increase_bn.bias\", \"conv2_2_1x1_increase_bn.running_mean\", \"conv2_2_1x1_increase_bn.running_var\", \"conv2_3_1x1_reduce.weight\", \"conv2_3_1x1_reduce_bn.weight\", \"conv2_3_1x1_reduce_bn.bias\", \"conv2_3_1x1_reduce_bn.running_mean\", \"conv2_3_1x1_reduce_bn.running_var\", \"conv2_3_3x3.weight\", \"conv2_3_3x3_bn.weight\", \"conv2_3_3x3_bn.bias\", \"conv2_3_3x3_bn.running_mean\", \"conv2_3_3x3_bn.running_var\", \"conv2_3_1x1_increase.weight\", \"conv2_3_1x1_increase_bn.weight\", \"conv2_3_1x1_increase_bn.bias\", \"conv2_3_1x1_increase_bn.running_mean\", \"conv2_3_1x1_increase_bn.running_var\", \"conv3_1_1x1_reduce.weight\", \"conv3_1_1x1_reduce_bn.weight\", \"conv3_1_1x1_reduce_bn.bias\", \"conv3_1_1x1_reduce_bn.running_mean\", \"conv3_1_1x1_reduce_bn.running_var\", \"conv3_1_3x3.weight\", \"conv3_1_3x3_bn.weight\", \"conv3_1_3x3_bn.bias\", \"conv3_1_3x3_bn.running_mean\", \"conv3_1_3x3_bn.running_var\", \"conv3_1_1x1_increase.weight\", \"conv3_1_1x1_increase_bn.weight\", \"conv3_1_1x1_increase_bn.bias\", \"conv3_1_1x1_increase_bn.running_mean\", \"conv3_1_1x1_increase_bn.running_var\", \"conv3_1_1x1_proj.weight\", \"conv3_1_1x1_proj_bn.weight\", \"conv3_1_1x1_proj_bn.bias\", \"conv3_1_1x1_proj_bn.running_mean\", \"conv3_1_1x1_proj_bn.running_var\", \"conv3_2_1x1_reduce.weight\", \"conv3_2_1x1_reduce_bn.weight\", \"conv3_2_1x1_reduce_bn.bias\", \"conv3_2_1x1_reduce_bn.running_mean\", \"conv3_2_1x1_reduce_bn.running_var\", \"conv3_2_3x3.weight\", \"conv3_2_3x3_bn.weight\", \"conv3_2_3x3_bn.bias\", \"conv3_2_3x3_bn.running_mean\", \"conv3_2_3x3_bn.running_var\", \"conv3_2_1x1_increase.weight\", \"conv3_2_1x1_increase_bn.weight\", \"conv3_2_1x1_increase_bn.bias\", \"conv3_2_1x1_increase_bn.running_mean\", \"conv3_2_1x1_increase_bn.running_var\", \"conv3_3_1x1_reduce.weight\", \"conv3_3_1x1_reduce_bn.weight\", \"conv3_3_1x1_reduce_bn.bias\", \"conv3_3_1x1_reduce_bn.running_mean\", \"conv3_3_1x1_reduce_bn.running_var\", \"conv3_3_3x3.weight\", \"conv3_3_3x3_bn.weight\", \"conv3_3_3x3_bn.bias\", \"conv3_3_3x3_bn.running_mean\", \"conv3_3_3x3_bn.running_var\", \"conv3_3_1x1_increase.weight\", \"conv3_3_1x1_increase_bn.weight\", \"conv3_3_1x1_increase_bn.bias\", \"conv3_3_1x1_increase_bn.running_mean\", \"conv3_3_1x1_increase_bn.running_var\", \"conv3_4_1x1_reduce.weight\", \"conv3_4_1x1_reduce_bn.weight\", \"conv3_4_1x1_reduce_bn.bias\", \"conv3_4_1x1_reduce_bn.running_mean\", \"conv3_4_1x1_reduce_bn.running_var\", \"conv3_4_3x3.weight\", \"conv3_4_3x3_bn.weight\", \"conv3_4_3x3_bn.bias\", \"conv3_4_3x3_bn.running_mean\", \"conv3_4_3x3_bn.running_var\", \"conv3_4_1x1_increase.weight\", \"conv3_4_1x1_increase_bn.weight\", \"conv3_4_1x1_increase_bn.bias\", \"conv3_4_1x1_increase_bn.running_mean\", \"conv3_4_1x1_increase_bn.running_var\", \"conv4_1_1x1_reduce.weight\", \"conv4_1_1x1_reduce_bn.weight\", \"conv4_1_1x1_reduce_bn.bias\", \"conv4_1_1x1_reduce_bn.running_mean\", \"conv4_1_1x1_reduce_bn.running_var\", \"conv4_1_3x3.weight\", \"conv4_1_3x3_bn.weight\", \"conv4_1_3x3_bn.bias\", \"conv4_1_3x3_bn.running_mean\", \"conv4_1_3x3_bn.running_var\", \"conv4_1_1x1_increase.weight\", \"conv4_1_1x1_increase_bn.weight\", \"conv4_1_1x1_increase_bn.bias\", \"conv4_1_1x1_increase_bn.running_mean\", \"conv4_1_1x1_increase_bn.running_var\", \"conv4_1_1x1_proj.weight\", \"conv4_1_1x1_proj_bn.weight\", \"conv4_1_1x1_proj_bn.bias\", \"conv4_1_1x1_proj_bn.running_mean\", \"conv4_1_1x1_proj_bn.running_var\", \"conv4_2_1x1_reduce.weight\", \"conv4_2_1x1_reduce_bn.weight\", \"conv4_2_1x1_reduce_bn.bias\", \"conv4_2_1x1_reduce_bn.running_mean\", \"conv4_2_1x1_reduce_bn.running_var\", \"conv4_2_3x3.weight\", \"conv4_2_3x3_bn.weight\", \"conv4_2_3x3_bn.bias\", \"conv4_2_3x3_bn.running_mean\", \"conv4_2_3x3_bn.running_var\", \"conv4_2_1x1_increase.weight\", \"conv4_2_1x1_increase_bn.weight\", \"conv4_2_1x1_increase_bn.bias\", \"conv4_2_1x1_increase_bn.running_mean\", \"conv4_2_1x1_increase_bn.running_var\", \"conv4_3_1x1_reduce.weight\", \"conv4_3_1x1_reduce_bn.weight\", \"conv4_3_1x1_reduce_bn.bias\", \"conv4_3_1x1_reduce_bn.running_mean\", \"conv4_3_1x1_reduce_bn.running_var\", \"conv4_3_3x3.weight\", \"conv4_3_3x3_bn.weight\", \"conv4_3_3x3_bn.bias\", \"conv4_3_3x3_bn.running_mean\", \"conv4_3_3x3_bn.running_var\", \"conv4_3_1x1_increase.weight\", \"conv4_3_1x1_increase_bn.weight\", \"conv4_3_1x1_increase_bn.bias\", \"conv4_3_1x1_increase_bn.running_mean\", \"conv4_3_1x1_increase_bn.running_var\", \"conv4_4_1x1_reduce.weight\", \"conv4_4_1x1_reduce_bn.weight\", \"conv4_4_1x1_reduce_bn.bias\", \"conv4_4_1x1_reduce_bn.running_mean\", \"conv4_4_1x1_reduce_bn.running_var\", \"conv4_4_3x3.weight\", \"conv4_4_3x3_bn.weight\", \"conv4_4_3x3_bn.bias\", \"conv4_4_3x3_bn.running_mean\", \"conv4_4_3x3_bn.running_var\", \"conv4_4_1x1_increase.weight\", \"conv4_4_1x1_increase_bn.weight\", \"conv4_4_1x1_increase_bn.bias\", \"conv4_4_1x1_increase_bn.running_mean\", \"conv4_4_1x1_increase_bn.running_var\", \"conv4_5_1x1_reduce.weight\", \"conv4_5_1x1_reduce_bn.weight\", \"conv4_5_1x1_reduce_bn.bias\", \"conv4_5_1x1_reduce_bn.running_mean\", \"conv4_5_1x1_reduce_bn.running_var\", \"conv4_5_3x3.weight\", \"conv4_5_3x3_bn.weight\", \"conv4_5_3x3_bn.bias\", \"conv4_5_3x3_bn.running_mean\", \"conv4_5_3x3_bn.running_var\", \"conv4_5_1x1_increase.weight\", \"conv4_5_1x1_increase_bn.weight\", \"conv4_5_1x1_increase_bn.bias\", \"conv4_5_1x1_increase_bn.running_mean\", \"conv4_5_1x1_increase_bn.running_var\", \"conv4_6_1x1_reduce.weight\", \"conv4_6_1x1_reduce_bn.weight\", \"conv4_6_1x1_reduce_bn.bias\", \"conv4_6_1x1_reduce_bn.running_mean\", \"conv4_6_1x1_reduce_bn.running_var\", \"conv4_6_3x3.weight\", \"conv4_6_3x3_bn.weight\", \"conv4_6_3x3_bn.bias\", \"conv4_6_3x3_bn.running_mean\", \"conv4_6_3x3_bn.running_var\", \"conv4_6_1x1_increase.weight\", \"conv4_6_1x1_increase_bn.weight\", \"conv4_6_1x1_increase_bn.bias\", \"conv4_6_1x1_increase_bn.running_mean\", \"conv4_6_1x1_increase_bn.running_var\", \"conv5_1_1x1_reduce.weight\", \"conv5_1_1x1_reduce_bn.weight\", \"conv5_1_1x1_reduce_bn.bias\", \"conv5_1_1x1_reduce_bn.running_mean\", \"conv5_1_1x1_reduce_bn.running_var\", \"conv5_1_3x3.weight\", \"conv5_1_3x3_bn.weight\", \"conv5_1_3x3_bn.bias\", \"conv5_1_3x3_bn.running_mean\", \"conv5_1_3x3_bn.running_var\", \"conv5_1_1x1_increase.weight\", \"conv5_1_1x1_increase_bn.weight\", \"conv5_1_1x1_increase_bn.bias\", \"conv5_1_1x1_increase_bn.running_mean\", \"conv5_1_1x1_increase_bn.running_var\", \"conv5_1_1x1_proj.weight\", \"conv5_1_1x1_proj_bn.weight\", \"conv5_1_1x1_proj_bn.bias\", \"conv5_1_1x1_proj_bn.running_mean\", \"conv5_1_1x1_proj_bn.running_var\", \"conv5_2_1x1_reduce.weight\", \"conv5_2_1x1_reduce_bn.weight\", \"conv5_2_1x1_reduce_bn.bias\", \"conv5_2_1x1_reduce_bn.running_mean\", \"conv5_2_1x1_reduce_bn.running_var\", \"conv5_2_3x3.weight\", \"conv5_2_3x3_bn.weight\", \"conv5_2_3x3_bn.bias\", \"conv5_2_3x3_bn.running_mean\", \"conv5_2_3x3_bn.running_var\", \"conv5_2_1x1_increase.weight\", \"conv5_2_1x1_increase_bn.weight\", \"conv5_2_1x1_increase_bn.bias\", \"conv5_2_1x1_increase_bn.running_mean\", \"conv5_2_1x1_increase_bn.running_var\", \"conv5_3_1x1_reduce.weight\", \"conv5_3_1x1_reduce_bn.weight\", \"conv5_3_1x1_reduce_bn.bias\", \"conv5_3_1x1_reduce_bn.running_mean\", \"conv5_3_1x1_reduce_bn.running_var\", \"conv5_3_3x3.weight\", \"conv5_3_3x3_bn.weight\", \"conv5_3_3x3_bn.bias\", \"conv5_3_3x3_bn.running_mean\", \"conv5_3_3x3_bn.running_var\", \"conv5_3_1x1_increase.weight\", \"conv5_3_1x1_increase_bn.weight\", \"conv5_3_1x1_increase_bn.bias\", \"conv5_3_1x1_increase_bn.running_mean\", \"conv5_3_1x1_increase_bn.running_var\", \"classifier.weight\", \"classifier.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/media/gnort/HDD6/Downloads_New/Compress/archive/resnet50_ft_dag.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m                   map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m device_ids[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# model = torch.nn.DataParallel(model, device_ids=[0])\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/gnort/HDD6/Study/face-analysis-lightning/pl-hydra/lib/python3.10/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"conv1_7x7_s2.weight\", \"conv1_7x7_s2_bn.weight\", \"conv1_7x7_s2_bn.bias\", \"conv1_7x7_s2_bn.running_mean\", \"conv1_7x7_s2_bn.running_var\", \"conv2_1_1x1_reduce.weight\", \"conv2_1_1x1_reduce_bn.weight\", \"conv2_1_1x1_reduce_bn.bias\", \"conv2_1_1x1_reduce_bn.running_mean\", \"conv2_1_1x1_reduce_bn.running_var\", \"conv2_1_3x3.weight\", \"conv2_1_3x3_bn.weight\", \"conv2_1_3x3_bn.bias\", \"conv2_1_3x3_bn.running_mean\", \"conv2_1_3x3_bn.running_var\", \"conv2_1_1x1_increase.weight\", \"conv2_1_1x1_increase_bn.weight\", \"conv2_1_1x1_increase_bn.bias\", \"conv2_1_1x1_increase_bn.running_mean\", \"conv2_1_1x1_increase_bn.running_var\", \"conv2_1_1x1_proj.weight\", \"conv2_1_1x1_proj_bn.weight\", \"conv2_1_1x1_proj_bn.bias\", \"conv2_1_1x1_proj_bn.running_mean\", \"conv2_1_1x1_proj_bn.running_var\", \"conv2_2_1x1_reduce.weight\", \"conv2_2_1x1_reduce_bn.weight\", \"conv2_2_1x1_reduce_bn.bias\", \"conv2_2_1x1_reduce_bn.running_mean\", \"conv2_2_1x1_reduce_bn.running_var\", \"conv2_2_3x3.weight\", \"conv2_2_3x3_bn.weight\", \"conv2_2_3x3_bn.bias\", \"conv2_2_3x3_bn.running_mean\", \"conv2_2_3x3_bn.running_var\", \"conv2_2_1x1_increase.weight\", \"conv2_2_1x1_increase_bn.weight\", \"conv2_2_1x1_increase_bn.bias\", \"conv2_2_1x1_increase_bn.running_mean\", \"conv2_2_1x1_increase_bn.running_var\", \"conv2_3_1x1_reduce.weight\", \"conv2_3_1x1_reduce_bn.weight\", \"conv2_3_1x1_reduce_bn.bias\", \"conv2_3_1x1_reduce_bn.running_mean\", \"conv2_3_1x1_reduce_bn.running_var\", \"conv2_3_3x3.weight\", \"conv2_3_3x3_bn.weight\", \"conv2_3_3x3_bn.bias\", \"conv2_3_3x3_bn.running_mean\", \"conv2_3_3x3_bn.running_var\", \"conv2_3_1x1_increase.weight\", \"conv2_3_1x1_increase_bn.weight\", \"conv2_3_1x1_increase_bn.bias\", \"conv2_3_1x1_increase_bn.running_mean\", \"conv2_3_1x1_increase_bn.running_var\", \"conv3_1_1x1_reduce.weight\", \"conv3_1_1x1_reduce_bn.weight\", \"conv3_1_1x1_reduce_bn.bias\", \"conv3_1_1x1_reduce_bn.running_mean\", \"conv3_1_1x1_reduce_bn.running_var\", \"conv3_1_3x3.weight\", \"conv3_1_3x3_bn.weight\", \"conv3_1_3x3_bn.bias\", \"conv3_1_3x3_bn.running_mean\", \"conv3_1_3x3_bn.running_var\", \"conv3_1_1x1_increase.weight\", \"conv3_1_1x1_increase_bn.weight\", \"conv3_1_1x1_increase_bn.bias\", \"conv3_1_1x1_increase_bn.running_mean\", \"conv3_1_1x1_increase_bn.running_var\", \"conv3_1_1x1_proj.weight\", \"conv3_1_1x1_proj_bn.weight\", \"conv3_1_1x1_proj_bn.bias\", \"conv3_1_1x1_proj_bn.running_mean\", \"conv3_1_1x1_proj_bn.running_var\", \"conv3_2_1x1_reduce.weight\", \"conv3_2_1x1_reduce_bn.weight\", \"conv3_2_1x1_reduce_bn.bias\", \"conv3_2_1x1_reduce_bn.running_mean\", \"conv3_2_1x1_reduce_bn.running_var\", \"conv3_2_3x3.weight\", \"conv3_2_3x3_bn.weight\", \"conv3_2_3x3_bn.bias\", \"conv3_2_3x3_bn.running_mean\", \"conv3_2_3x3_bn.running_var\", \"conv3_2_1x1_increase.weight\", \"conv3_2_1x1_increase_bn.weight\", \"conv3_2_1x1_increase_bn.bias\", \"conv3_2_1x1_increase_bn.running_mean\", \"conv3_2_1x1_increase_bn.running_var\", \"conv3_3_1x1_reduce.weight\", \"conv3_3_1x1_reduce_bn.weight\", \"conv3_3_1x1_reduce_bn.bias\", \"conv3_3_1x1_reduce_bn.running_mean\", \"conv3_3_1x1_reduce_bn.running_var\", \"conv3_3_3x3.weight\", \"conv3_3_3x3_bn.weight\", \"conv3_3_3x3_bn.bias\", \"conv3_3_3x3_bn.running_mean\", \"conv3_3_3x3_bn.running_var\", \"conv3_3_1x1_increase.weight\", \"conv3_3_1x1_increase_bn.weight\", \"conv3_3_1x1_increase_bn.bias\", \"conv3_3_1x1_increase_bn.running_mean\", \"conv3_3_1x1_increase_bn.running_var\", \"conv3_4_1x1_reduce.weight\", \"conv3_4_1x1_reduce_bn.weight\", \"conv3_4_1x1_reduce_bn.bias\", \"conv3_4_1x1_reduce_bn.running_mean\", \"conv3_4_1x1_reduce_bn.running_var\", \"conv3_4_3x3.weight\", \"conv3_4_3x3_bn.weight\", \"conv3_4_3x3_bn.bias\", \"conv3_4_3x3_bn.running_mean\", \"conv3_4_3x3_bn.running_var\", \"conv3_4_1x1_increase.weight\", \"conv3_4_1x1_increase_bn.weight\", \"conv3_4_1x1_increase_bn.bias\", \"conv3_4_1x1_increase_bn.running_mean\", \"conv3_4_1x1_increase_bn.running_var\", \"conv4_1_1x1_reduce.weight\", \"conv4_1_1x1_reduce_bn.weight\", \"conv4_1_1x1_reduce_bn.bias\", \"conv4_1_1x1_reduce_bn.running_mean\", \"conv4_1_1x1_reduce_bn.running_var\", \"conv4_1_3x3.weight\", \"conv4_1_3x3_bn.weight\", \"conv4_1_3x3_bn.bias\", \"conv4_1_3x3_bn.running_mean\", \"conv4_1_3x3_bn.running_var\", \"conv4_1_1x1_increase.weight\", \"conv4_1_1x1_increase_bn.weight\", \"conv4_1_1x1_increase_bn.bias\", \"conv4_1_1x1_increase_bn.running_mean\", \"conv4_1_1x1_increase_bn.running_var\", \"conv4_1_1x1_proj.weight\", \"conv4_1_1x1_proj_bn.weight\", \"conv4_1_1x1_proj_bn.bias\", \"conv4_1_1x1_proj_bn.running_mean\", \"conv4_1_1x1_proj_bn.running_var\", \"conv4_2_1x1_reduce.weight\", \"conv4_2_1x1_reduce_bn.weight\", \"conv4_2_1x1_reduce_bn.bias\", \"conv4_2_1x1_reduce_bn.running_mean\", \"conv4_2_1x1_reduce_bn.running_var\", \"conv4_2_3x3.weight\", \"conv4_2_3x3_bn.weight\", \"conv4_2_3x3_bn.bias\", \"conv4_2_3x3_bn.running_mean\", \"conv4_2_3x3_bn.running_var\", \"conv4_2_1x1_increase.weight\", \"conv4_2_1x1_increase_bn.weight\", \"conv4_2_1x1_increase_bn.bias\", \"conv4_2_1x1_increase_bn.running_mean\", \"conv4_2_1x1_increase_bn.running_var\", \"conv4_3_1x1_reduce.weight\", \"conv4_3_1x1_reduce_bn.weight\", \"conv4_3_1x1_reduce_bn.bias\", \"conv4_3_1x1_reduce_bn.running_mean\", \"conv4_3_1x1_reduce_bn.running_var\", \"conv4_3_3x3.weight\", \"conv4_3_3x3_bn.weight\", \"conv4_3_3x3_bn.bias\", \"conv4_3_3x3_bn.running_mean\", \"conv4_3_3x3_bn.running_var\", \"conv4_3_1x1_increase.weight\", \"conv4_3_1x1_increase_bn.weight\", \"conv4_3_1x1_increase_bn.bias\", \"conv4_3_1x1_increase_bn.running_mean\", \"conv4_3_1x1_increase_bn.running_var\", \"conv4_4_1x1_reduce.weight\", \"conv4_4_1x1_reduce_bn.weight\", \"conv4_4_1x1_reduce_bn.bias\", \"conv4_4_1x1_reduce_bn.running_mean\", \"conv4_4_1x1_reduce_bn.running_var\", \"conv4_4_3x3.weight\", \"conv4_4_3x3_bn.weight\", \"conv4_4_3x3_bn.bias\", \"conv4_4_3x3_bn.running_mean\", \"conv4_4_3x3_bn.running_var\", \"conv4_4_1x1_increase.weight\", \"conv4_4_1x1_increase_bn.weight\", \"conv4_4_1x1_increase_bn.bias\", \"conv4_4_1x1_increase_bn.running_mean\", \"conv4_4_1x1_increase_bn.running_var\", \"conv4_5_1x1_reduce.weight\", \"conv4_5_1x1_reduce_bn.weight\", \"conv4_5_1x1_reduce_bn.bias\", \"conv4_5_1x1_reduce_bn.running_mean\", \"conv4_5_1x1_reduce_bn.running_var\", \"conv4_5_3x3.weight\", \"conv4_5_3x3_bn.weight\", \"conv4_5_3x3_bn.bias\", \"conv4_5_3x3_bn.running_mean\", \"conv4_5_3x3_bn.running_var\", \"conv4_5_1x1_increase.weight\", \"conv4_5_1x1_increase_bn.weight\", \"conv4_5_1x1_increase_bn.bias\", \"conv4_5_1x1_increase_bn.running_mean\", \"conv4_5_1x1_increase_bn.running_var\", \"conv4_6_1x1_reduce.weight\", \"conv4_6_1x1_reduce_bn.weight\", \"conv4_6_1x1_reduce_bn.bias\", \"conv4_6_1x1_reduce_bn.running_mean\", \"conv4_6_1x1_reduce_bn.running_var\", \"conv4_6_3x3.weight\", \"conv4_6_3x3_bn.weight\", \"conv4_6_3x3_bn.bias\", \"conv4_6_3x3_bn.running_mean\", \"conv4_6_3x3_bn.running_var\", \"conv4_6_1x1_increase.weight\", \"conv4_6_1x1_increase_bn.weight\", \"conv4_6_1x1_increase_bn.bias\", \"conv4_6_1x1_increase_bn.running_mean\", \"conv4_6_1x1_increase_bn.running_var\", \"conv5_1_1x1_reduce.weight\", \"conv5_1_1x1_reduce_bn.weight\", \"conv5_1_1x1_reduce_bn.bias\", \"conv5_1_1x1_reduce_bn.running_mean\", \"conv5_1_1x1_reduce_bn.running_var\", \"conv5_1_3x3.weight\", \"conv5_1_3x3_bn.weight\", \"conv5_1_3x3_bn.bias\", \"conv5_1_3x3_bn.running_mean\", \"conv5_1_3x3_bn.running_var\", \"conv5_1_1x1_increase.weight\", \"conv5_1_1x1_increase_bn.weight\", \"conv5_1_1x1_increase_bn.bias\", \"conv5_1_1x1_increase_bn.running_mean\", \"conv5_1_1x1_increase_bn.running_var\", \"conv5_1_1x1_proj.weight\", \"conv5_1_1x1_proj_bn.weight\", \"conv5_1_1x1_proj_bn.bias\", \"conv5_1_1x1_proj_bn.running_mean\", \"conv5_1_1x1_proj_bn.running_var\", \"conv5_2_1x1_reduce.weight\", \"conv5_2_1x1_reduce_bn.weight\", \"conv5_2_1x1_reduce_bn.bias\", \"conv5_2_1x1_reduce_bn.running_mean\", \"conv5_2_1x1_reduce_bn.running_var\", \"conv5_2_3x3.weight\", \"conv5_2_3x3_bn.weight\", \"conv5_2_3x3_bn.bias\", \"conv5_2_3x3_bn.running_mean\", \"conv5_2_3x3_bn.running_var\", \"conv5_2_1x1_increase.weight\", \"conv5_2_1x1_increase_bn.weight\", \"conv5_2_1x1_increase_bn.bias\", \"conv5_2_1x1_increase_bn.running_mean\", \"conv5_2_1x1_increase_bn.running_var\", \"conv5_3_1x1_reduce.weight\", \"conv5_3_1x1_reduce_bn.weight\", \"conv5_3_1x1_reduce_bn.bias\", \"conv5_3_1x1_reduce_bn.running_mean\", \"conv5_3_1x1_reduce_bn.running_var\", \"conv5_3_3x3.weight\", \"conv5_3_3x3_bn.weight\", \"conv5_3_3x3_bn.bias\", \"conv5_3_3x3_bn.running_mean\", \"conv5_3_3x3_bn.running_var\", \"conv5_3_1x1_increase.weight\", \"conv5_3_1x1_increase_bn.weight\", \"conv5_3_1x1_increase_bn.bias\", \"conv5_3_1x1_increase_bn.running_mean\", \"conv5_3_1x1_increase_bn.running_var\", \"classifier.weight\", \"classifier.bias\". "
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50\n",
    "import torch\n",
    "model = resnet50()\n",
    "device_ids = [0]\n",
    "ckpt = torch.load(\"/media/gnort/HDD6/Downloads_New/Compress/archive/resnet50_ft_dag.pth\",\n",
    "                  map_location='cuda:%d' % device_ids[0])\n",
    "# model = torch.nn.DataParallel(model, device_ids=[0])\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
