# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: all
  - override /model: backbone_heads
  - override /callbacks: default
  - override /trainer: gpu
  - override /logger: wandb

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["all", "all_classifier"]

seed: 12345

data:
  num_workers: 4
  root_dir: /media/gnort/HDD6/Study/face-analysis-lightning/dataset/face/aligned_faces_added_race
  image_train_list: /media/gnort/HDD6/Study/face-analysis-lightning/dataset/face/image_lists/face_train_added_race.txt
  image_test_list: /media/gnort/HDD6/Study/face-analysis-lightning/dataset/face/image_lists/face_test.txt
  mean: [0.5, 0.5, 0.5]
  std: [0.5, 0.5, 0.5]
  image_size: 256
  crop_size: 224
  backbone_name: ${model.backbone.name}

trainer:
  accelerator: gpu
  min_epochs: 20
  max_epochs: 100
  gradient_clip_val: 0.5

model:
  optimizer:
    lr: 0.002
  criterion:
    # _target_: src.losses.focal_loss.FocalLoss
    _target_: src.losses.loss.CrossEntropyLoss
    # gamma: 2.0
    # alpha: [0.15, 0.15, 0.7]
  attributes: [["masked", 1]]
  
  race_head:
    _target_: src.models.components.maksed_classifier.MaskedClassifier
    output_size: 1
    num_of_features: 512

  backbone:
    _target_: src.models.components.backbone_maker.BackboneMaker  
    name: inception_resnet_v1 # timm format
    pretrained: true
    checkpoint_path: /media/gnort/HDD6/Study/face-analysis-lightning/weights/20180402-114759-vggface2.pt

callbacks:
  early_stopping:
    mode: "max"
  
logger:
  wandb:
    tags: ${tags}
    group: "f_all"
  aim:
    experiment: "f_all"


